{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Assignment 2:- Supervised Learning: Regression Models and Performance Metrics**\n",
        "\n",
        "**Question 1:** What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "**Answer:** **Simple Linear Regression (SLR)** is a **statistical method** used to model the relationship between two variables ‚Äî one independent variable (X) and one dependent variable (Y) ‚Äî by fitting a straight line to the observed data.\n",
        "\n",
        "üîπ **Definition**\n",
        "\n",
        "In simple terms, SLR estimates how much the dependent variable\n",
        "ùëå changes when the independent variable\n",
        "ùëã changes by one unit.\n",
        "\n",
        "The mathematical form of the model is:\n",
        "\n",
        "ùëå = Œ≤0 + Œ≤1 ùëã + Œµ\n",
        "\n",
        "where:\n",
        "\n",
        "ùëå = dependent (response) variable\n",
        "\n",
        "ùëã = independent (predictor) variable\n",
        "\n",
        "ùõΩ0 = intercept (value of ùëå when ùëã = 0)\n",
        "\n",
        "ùõΩ1 = slope (rate of change of ùëå with respect to ùëã)\n",
        "\n",
        "ùúÄ = random error term (captures variability not explained by ùëã)\n",
        "\n",
        "üîπ **Purpose of Simple Linear Regression**\n",
        "\n",
        "The main goals of SLR are:\n",
        "\n",
        "1. **Prediction:**   \n",
        "Estimate or predict the value of ùëå for a given value of ùëã.  \n",
        "Example: Predicting a student‚Äôs exam score based on study hours.\n",
        "\n",
        "2. **Understanding relationships:**  \n",
        "Determine whether and how strongly two variables are linearly related.  \n",
        "Example: Analyzing whether advertising spending influences sales.\n",
        "\n",
        "3. **Quantifying effect:**  \n",
        "The slope ùõΩ1 quantifies how much ùëå changes on average for a one-unit increase in ùëã.\n",
        "\n",
        "üîπ **Assumptions of SLR**\n",
        "\n",
        "1. Linearity: The relationship between ùëã and ùëå is linear.\n",
        "\n",
        "2. Independence: Observations are independent.\n",
        "\n",
        "3. Homoscedasticity: The variance of errors is constant.\n",
        "\n",
        "4. Normality: The residuals (errors) are normally distributed.\n",
        "\n",
        "üîπ **Example**\n",
        "\n",
        "Suppose we study how **hours studied (X)** affect **exam scores (Y)**.\n",
        "Data might show that each additional hour of study increases the score by 5 points, leading to the regression equation:\n",
        "\n",
        ">> Score = 40 + 5 x Hours studied\n",
        "\n",
        "So, if a student studies for 6 hours, the predicted score is 40 + 5 (6) = 70\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Question 2:** What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "**Answer:** The **key assumptions of Simple Linear Regression (SLR)** ensure that the model‚Äôs estimates are valid, reliable, and interpretable. Violating these assumptions can lead to incorrect conclusions or biased predictions.\n",
        "\n",
        "Here are the **five main assumptions** explained clearly:\n",
        "\n",
        "üîπ **1. Linearity**\n",
        "\n",
        "- **Meaning:** The relationship between the independent variable ùëã and the dependent variable ùëå must be linear.\n",
        "\n",
        "- **In other words:** The change in ùëå should be proportional to the change in ùëã.\n",
        "\n",
        "- **How to check:** Plot a scatter plot of ùëã vs. ùëå. The data points should roughly form a straight-line pattern.\n",
        "\n",
        "üîπ **2. Independence of Errors**\n",
        "\n",
        "- **Meaning:** The residuals (errors) ‚Äî differences between observed and predicted values ‚Äî must be **independent** of each other.\n",
        "\n",
        "- **Why it matters:** If errors are correlated (e.g., in time-series data), predictions and statistical tests become unreliable.\n",
        "\n",
        "- **How to check:** Use the **Durbin-Watson test** (especially for time-series data).\n",
        "\n",
        "üîπ **3. Homoscedasticity (Constant Variance of Errors)**\n",
        "\n",
        "- **Meaning:** The variance of the residuals should be constant across all levels of **ùëã**.\n",
        "\n",
        "\n",
        "- **Why it matters:** If the spread of residuals increases or decreases with **ùëã** (called heteroscedasticity), it can distort standard errors and confidence intervals.\n",
        "\n",
        "- **How to check:** Plot residuals vs. predicted values ‚Äî they should form a random scatter (not a funnel shape).\n",
        "\n",
        "üîπ **4. Normality of Errors**\n",
        "\n",
        "- **Meaning:** The residuals should be **approximately normally distributed**.\n",
        "\n",
        "- **Why it matters:** This assumption is important for hypothesis testing and constructing confidence intervals.\n",
        "\n",
        "- **How to check:** Use a **histogram** or **Q‚ÄìQ plot** of residuals ‚Äî they should follow a bell-shaped curve.\n",
        "\n",
        "üîπ **5. No (or minimal) Multicollinearity**\n",
        "\n",
        "- In **simple** linear regression (only one independent variable), this isn‚Äôt an issue.\n",
        "\n",
        "- In **multiple** regression, it means that independent variables should not be highly correlated with each other.\n",
        "\n",
        "---\n",
        "\n",
        "**Question 3:**  Write the mathematical equation for a simple linear regression model and explain each term.\n",
        "\n",
        "**Answer:** >The **mathematical equation** for a **Simple Linear Regression (SLR)** model is:\n",
        "\n",
        ">>Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œµ\n",
        "\n",
        ">**Explanation of Each Term**\n",
        "\n",
        "| **Term**           | **Name**                        | **Meaning / Role**                                                                                                                                |\n",
        "| ------------------ | ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Y**              | Dependent Variable              | The variable we want to **predict or explain**. <br>Example: Marks scored, house price, etc.                                                      |\n",
        "| **X**              | Independent Variable            | The variable used to **predict Y**. <br>Example: Hours studied, area of the house, etc.                                                           |\n",
        "| **Œ≤‚ÇÄ (Beta-zero)** | Intercept                       | The **value of Y when X = 0**. <br>It represents the baseline or starting value.                                                                  |\n",
        "| **Œ≤‚ÇÅ (Beta-one)**  | Slope or Regression Coefficient | Shows how much **Y changes** for a **one-unit increase in X**. <br>If Œ≤‚ÇÅ = 5, then for every 1 increase in X, Y increases by 5 units.             |\n",
        "| **Œµ (Epsilon)**    | Error Term or Residual          | Represents the **difference** between the **actual** and **predicted** Y values. <br>It captures randomness or factors not included in the model. |\n",
        "\n",
        "\n",
        ">**Example**\n",
        "\n",
        ">Suppose we are predicting **marks (Y)** based on **hours studied (X)**:\n",
        "\n",
        "$Y = 40 + 5X + Œµ$\n",
        "\n",
        "\n",
        ">Here:\n",
        "\n",
        ">* **Œ≤‚ÇÄ = 40** ‚Üí Base marks if no hours are studied.\n",
        ">* **Œ≤‚ÇÅ = 5** ‚Üí For every extra hour studied, marks increase by 5.\n",
        ">* **Œµ** ‚Üí Random error due to factors like mood, environment, or luck.\n",
        "\n",
        "---\n",
        "\n",
        "**Question 4:**  Provide a real-world example where simple linear regression can be applied.\n",
        "\n",
        "**Answer:** Here‚Äôs a clear real-world example of how Simple Linear Regression (SLR) can be applied.\n",
        "\n",
        "üéØ **Example: Predicting House Prices Based on Size**\n",
        "\n",
        "**Scenario:**\n",
        "\n",
        "A real estate company wants to **predict the price of a house** based on its **size (in square feet)**.\n",
        "\n",
        "**Variables:**\n",
        "\n",
        "- **Dependent variable (Y):** House price (in ‚Çπ or $)\n",
        "\n",
        "- **Independent variable (X):** Size of the house (in square feet)\n",
        "\n",
        "**Regression Model:**\n",
        "\n",
        ">>Price = ùõΩ0 + ùõΩ1 (Size) + ùúÄ\n",
        "\n",
        "\n",
        "\n",
        "**Where:**\n",
        "\n",
        "ùõΩ0 : The predicted price of a house with size = 0 (intercept)\n",
        "ùõΩ1 : The average increase in house price for every additional square foot\n",
        "ùúÄ: Random error (captures factors like location, condition, or neighborhood quality)\n",
        "\n",
        "---\n",
        "\n",
        "**Question 5:** What is the method of least squares in linear regression?\n",
        "\n",
        "**Answer:** The **method of least squares in linear regression** is a mathematical technique used to find the **best-fitting line** through a set of data points.\n",
        "\n",
        "üîπ **Concept:**\n",
        "\n",
        "It works by minimizing the **sum of the squares of the differences** (called **residuals**) between the **observed values** (actual data) and the **predicted values** (values given by the regression line).\n",
        "\n",
        "üîπ **Formula:**\n",
        "\n",
        "For a simple linear regression model:\n",
        "\n",
        "$$ùë¶ = ùëé + ùëèùë•$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $ùë¶$ = dependent variable (predicted value)\n",
        "* $ùë•$ = independent variable (input)\n",
        "* $ùëé$ = intercept\n",
        "* $ùëè$ = slope of the line\n",
        "\n",
        "The method of least squares minimizes this function:\n",
        "\n",
        "$$S = \\sum (y_i - (a + bx_i))^2$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $ùë¶ùëñ$ = actual value of\n",
        "\n",
        "* $ùë¶ (ùëé + ùëèùë•ùëñ)$= predicted value\n",
        "\n",
        "* $ùëÜ$ = sum of squared residuals\n",
        "\n",
        "üîπ **Goal:**\n",
        "\n",
        "Find values of\n",
        "$ùëé$ and $ùëè$ that make $ùëÜ$ as small as possible ‚Äî meaning the line fits the data points as closely as possible.\n",
        "\n",
        "üîπ **In simple terms:**\n",
        "\n",
        "It‚Äôs like drawing a line through a scatter plot so that the total distance (vertically) between the points and the line is as small as possible ‚Äî but we square those distances to avoid negative values and to emphasize larger errors.\n",
        "\n",
        "---\n",
        "\n",
        "**Question 6:** What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "**Answer:** **Logistic Regression** is a **statistical method** used for **binary classification** problems ‚Äî where the output (dependent variable) has **two possible** outcomes, such as:\n",
        "‚úÖ Yes / No\n",
        "‚úÖ Pass / Fail\n",
        "‚úÖ 1 / 0\n",
        "\n",
        "Despite its name, **Logistic Regression is used for classification, not regression.**\n",
        "\n",
        "It predicts the **probability** that a given input belongs to a particular class using the **logistic (sigmoid) function**, which outputs values between 0 and 1.\n",
        "\n",
        "üîπ **The Logistic Function (Sigmoid Function):**\n",
        "\n",
        "\n",
        "$$P (Y = 1|X) = \\frac{1}{1 + e^{-(b_0 + b_1x)}}$$\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "* $ùëÉ (ùëå = 1‚à£X)$ = probability that output is 1 (positive class)\n",
        "\n",
        "* $ùëè0$ = intercept\n",
        "\n",
        "* $ùëè1$ = coefficient (slope)\n",
        "\n",
        "* $ùëí$ = Euler‚Äôs number (~2.718)\n",
        "\n",
        "If $ùëÉ >0.5$, we classify the outcome as 1 (positive), otherwise 0 (negative).\n",
        "\n",
        "üîπ **Logistic Regression Differs from Linear Regression:**\n",
        "| **Aspect**            | **Linear Regression**                             | **Logistic Regression**                                       |                                      |\n",
        "| --------------------- | ------------------------------------------------- | ------------------------------------------------------------- | ------------------------------------ |\n",
        "| **Purpose**           | Predicts a continuous numeric value               | Predicts a categorical outcome (usually binary)               |                                      |\n",
        "| **Output Range**      | Any real number (‚àí‚àû to +‚àû)                        | Probability between 0 and 1                                   |                                      |\n",
        "| **Equation Form**     | $( y = b_0 + b_1x )$                                | ( P(Y=1                                                       |  |\n",
        "| **Error Metric**      | Mean Squared Error (MSE)                          | Log Loss or Cross-Entropy                                     |                                      |\n",
        "| **Decision Boundary** | Linear relationship between x and y               | Uses sigmoid function to create a nonlinear relationship      |                                      |\n",
        "| **Use Case Examples** | Predicting house prices, sales, temperature, etc. | Predicting spam/not spam, disease/no disease, pass/fail, etc. |                                      |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Question 7:** Name and briefly describe three common evaluation metrics for regression models.\n",
        "\n",
        "**Answer:** Here are **three common evaluation metrics** used to measure the performance of **regression models.**\n",
        "\n",
        "\n",
        "üîπ **1. Mean Absolute Error (MAE)**\n",
        "\n",
        "**Definition:**\n",
        "MAE measures the **average absolute difference** between the actual values and the predicted values.\n",
        "\n",
        "$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
        "\n",
        "**Meaning:**\n",
        "It tells us, on average, how far the predictions are from the actual values ‚Äî in the same units as the target variable.\n",
        "\n",
        "**Example:**\n",
        "If MAE = 5, the model‚Äôs predictions are off by about 5 units on average.\n",
        "\n",
        "\n",
        "üîπ **2. Mean Squared Error (MSE)**\n",
        "\n",
        "**Definition:**\n",
        "MSE measures the **average of the squared differences** between actual and predicted values.\n",
        "\n",
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "**Meaning:**\n",
        "It penalizes **larger errors** more than smaller ones because errors are squared.\n",
        "A lower MSE means better model performance.\n",
        "\n",
        "üîπ **3. R-squared (Coefficient of Determination)**\n",
        "\n",
        "**Definition:**\n",
        "R¬≤ explains how much of the **variance in the dependent** variable is explained by the model.\n",
        "\n",
        "$$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$\n",
        "\n",
        "**Meaning:**\n",
        "\n",
        "* $ùëÖ2 =1:$ Perfect fit\n",
        "\n",
        "* $ùëÖ2 = 0:$ Model explains none of the variance\n",
        "\n",
        "It shows the **goodness of fit** of the regression model.\n",
        "\n",
        "---\n",
        "\n",
        "**Question 8:** What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "**Answer:** **Purpose of R-squared Metric in Regression Analysis**\n",
        "\n",
        "**R-squared (R¬≤)**, also known as the **coefficient of determination**, measures how well the **regression model explains the variability** of the dependent variable (**Y**) based on the independent variable(s) (**X**).\n",
        "\n",
        "$$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$\n",
        "\n",
        "**Key Points**\n",
        "\n",
        "* **R¬≤ value ranges from 0 to 1:**\n",
        "\n",
        "* **0** ‚Üí Model explains none of the variation in Y.\n",
        "* **1** ‚Üí Model perfectly explains all the variation in Y.\n",
        "* It represents the **proportion of variance** in the dependent variable that is **explained by the independent variable(s)**.\n",
        "* Higher **R¬≤** indicates a **better model fit**.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "If a regression model has **R¬≤ = 0.85**, it means:\n",
        "\n",
        "85% of the variation in the dependent variable is explained by the model, and the remaining 15% is due to other unexplained factors (errors or noise).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "qRQvmJr4zSl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Question 9. Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.'''\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "# X = independent variable (reshape required for sklearn)\n",
        "# Y = dependent variable\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "Y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Print the slope (coefficient) and intercept\n",
        "print(\"Slope (Œ≤‚ÇÅ):\", model.coef_[0])\n",
        "print(\"Intercept (Œ≤‚ÇÄ):\", model.intercept_)\n",
        "\n",
        "# Optional: print predicted values\n",
        "Y_pred = model.predict(X)\n",
        "print(\"\\nPredicted values:\", Y_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "VkXv0suD45tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b0a5e1-07da-46c3-9bac-4da39a88fc10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Œ≤‚ÇÅ): 0.6\n",
            "Intercept (Œ≤‚ÇÄ): 2.2\n",
            "\n",
            "Predicted values: [2.8 3.4 4.  4.6 5.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10:** How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "**Answer:** In a **simple linear regression model**, the relationship between a dependent variable\n",
        "$ùë¶$ and an independent variable\n",
        "$ùë•$ is expressed as:\n",
        "\n",
        "$$y = \\beta_0 + \\beta_1 x + \\epsilon$$\n",
        "\n",
        "Here‚Äôs how to interpret the **coefficients:**\n",
        "\n",
        "**1. Intercept** $(\\beta_0)$\n",
        "\n",
        "* Also called the **constant term**.\n",
        "\n",
        "* It represents the **predicted value** of $ùë¶$ when $ùë• = 0$.\n",
        "\n",
        "In other words, it‚Äôs the starting point or baseline of the regression line on the y-axis.\n",
        "\n",
        "* Example: If $\\beta_ = 5$,it means that when\n",
        "$ùë• = 0$, the predicted value of $ùë¶$ is 5.\n",
        "\n",
        "**2. Slope** $(\\beta_1)$\n",
        "\n",
        "* Represents the **change in**\n",
        "$ùë¶$ for a **one-unit increase in** $ùë•$.\n",
        "\n",
        "* It shows the **strength and direction** of the relationship:\n",
        "\n",
        "  * If $\\beta_1 > 0: ùë¶$ increases as $ùë•$ increases (positive relationship).\n",
        "\n",
        "  * If $\\beta_1 > 0: ùë¶$ decreases as $ùë•$ increases (negative relationship).\n",
        "\n",
        "Example: If $\\beta_1 = 2$, it means for every one-unit increase in $ùë•,ùë¶$ is predicted to increase by 2 units.\n"
      ],
      "metadata": {
        "id": "wwSP191_YaVy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0vBQC_PeGqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}